{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51100857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Import Libraries ---\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "import warnings\n",
    "import sys # Using sys to exit cleanly if data is missing\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- 2. Load Processed Data ---\n",
    "print(\"Loading preprocessed data...\")\n",
    "# When running from the 'notebooks' folder, we need to go one level up (../) to find the data folder.\n",
    "try:\n",
    "    X_train = pd.read_csv('../data/processed/X_train_processed.csv')\n",
    "    y_train = pd.read_csv('../data/processed/y_train.csv').values.ravel()\n",
    "    print(\"Data loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Processed data not found.\")\n",
    "    print(\"Please ensure you have run the 'run_pipeline.py' script first from the root directory.\")\n",
    "    # Stop execution cleanly if data is not found\n",
    "    sys.exit()\n",
    "\n",
    "# --- 3. Define the Hyperparameter Tuning Objective Function ---\n",
    "def objective(trial, X, y):\n",
    "    \"\"\"\n",
    "    Defines the objective for Optuna to optimize.\n",
    "    A 'trial' is a single run with a specific set of hyperparameters.\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'verbosity': -1,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'n_estimators': 1000,\n",
    "        'class_weight': 'balanced',\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.4, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "    }\n",
    "\n",
    "    N_SPLITS = 5\n",
    "    skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
    "    f1_scores = []\n",
    "\n",
    "    # Use the passed X and y instead of global variables\n",
    "    for train_index, val_index in skf.split(X, y):\n",
    "        X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train_fold, y_val_fold = y[train_index], y[val_index]\n",
    "\n",
    "        model = lgb.LGBMClassifier(**params)\n",
    "        # Use a callback for early stopping\n",
    "        early_stopping_callback = lgb.early_stopping(100, verbose=False)\n",
    "        model.fit(X_train_fold, y_train_fold,\n",
    "                  eval_set=[(X_val_fold, y_val_fold)],\n",
    "                  eval_metric='f1',\n",
    "                  callbacks=[early_stopping_callback])\n",
    "\n",
    "        preds = model.predict(X_val_fold)\n",
    "        f1 = f1_score(y_val_fold, preds, pos_label=1)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "    return sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "# --- 4. Run the Optimization ---\n",
    "# This section will only run if the data was loaded successfully.\n",
    "print(\"Starting hyperparameter tuning with Optuna...\")\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "# Use a lambda function to pass X_train and y_train to our objective function\n",
    "study.optimize(lambda trial: objective(trial, X_train, y_train), n_trials=50)\n",
    "\n",
    "# --- 5. Display the Results ---\n",
    "print(\"\\nOptimization finished.\")\n",
    "print(\"Number of finished trials: \", len(study.trials))\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value (F1-score): \", trial.value)\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
